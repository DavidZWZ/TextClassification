#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Dec 13 14:27:48 2018

@author: jjg
"""

import pandas as pd
import numpy as np
from gensim.models import KeyedVectors as kv
from nltk.tokenize import word_tokenize
from sklearn import linear_model
from sklearn import metrics

#1.预处理

#(1)加载数据集
train = pd.read_csv('./dbpedia_csv/train.csv',header=None,sep=',',
               names=['label','title','text']) 
test = pd.read_csv('./dbpedia_csv/test.csv',header=None,sep=',',
               names=['label','title','text']) 

#(2)将标题正文相加得全文
train['full'] = train['title'].str.cat(train['text'],sep=' ')
test['full'] = test['title'].str.cat(test['text'],sep=' ')

#(3)分词(其他像去标点、去停用词、去常用词之类，暂时略过)
train['words'] = train['full'].apply(lambda x:word_tokenize(str(x)))
test['words'] = test['full'].apply(lambda x:word_tokenize(str(x)))

#2.词嵌入：求文本向量

#(1)载入模型
model = kv.load_word2vec_format('./GoogleNews-vectors-negative300.bin',
                                                    binary=True)


#(2)求文本向量
def doc2vec(text, model):
    """
    doc-to-vector
    :param text:
    :param model:
    :return: 文本向量
    """
    doc_vec = np.zeros(300)
    numw = 0
    for word in text:
        try:
            doc_vec = np.add(doc_vec, model[word])
            numw += 1
        except:
            pass
    return doc_vec


train['vec'] = train['words'].apply(lambda x:doc2vec(x,model))
test['vec'] = test['words'].apply(lambda x:doc2vec(x,model))
#train.to_csv("train_vec.csv") #太大了3个G，后面将主要数据保存为小一点的文件
#test.to_csv("test_vec.csv")

#将标题、文本向量单独保存起来，以减小文件大小
#train[['title','vec']].to_csv("train_title_vec.csv") #还是很大，说明主要是向量部分太占内存了
#test[['title','vec']].to_csv("test_title_vec.csv")

#3.训练、预测

#3.1调用sklearn的相应方法

def fit_and_predicted(train_x, train_y, test_x, test_y, penalty='l2', C=1.0, solver='sag'):
    """
    训练与预测
    :param train_x: 
    :param train_y: 
    :param test_x: 
    :param test_y: 
    :return: 
    """
    clf = linear_model.LogisticRegression(penalty=penalty, C=C, solver=solver, n_jobs=-1).fit(train_x, train_y)
    predicted = clf.predict(test_x)
    print(metrics.classification_report(test_y, predicted))
    print('accuracy_score: %0.5fs' %(metrics.accuracy_score(test_y, predicted)))


#3.2 调用fit方法时遇到ValueError: setting an array element with a sequence. 未能解决
from time import time
#train['label_arr'] = train['label'].apply(lambda x:np.array(x))
#test['label_arr'] = test['label'].apply(lambda x:np.array(x))
t0 = time()
fit_and_predicted(train['vec'],train['label'],test['vec'],test['label'])
t1 = time()
print('耗时：%.2f'%(t1-t0))

#猜测：很可能是在求向量时，其中含有缺失值，导致‘vec'列的有部分元素维度不同

temp = train.isnull().any() #列中是否存在空值
print(type(temp))
print(temp)  #结果显示每列都为False,所以每列都不存在空值

#将vec列的每个向量的所有维度都检查一遍
#from pandas import Series
#Series(train['vec'][0].tolist()).isnull()

 
#3.3 试着改写doc2vec函数,重新生成向量
vocab = list(model.vocab.keys())

def doc2vec_m1(text, model):
    """
    doc-to-vector,修改版1
    :param text:
    :param model:
    :return: 文本向量
    """
    doc_vec = np.zeros(300)
    numw = 0
    for word in text:
        if word in vocab:     #对每个词要查找最多约21次，五六十万的文本，每段40词左右，颇费时间
             doc_vec = np.add(doc_vec, model[word])
             numw += 1
    return doc_vec       

train['vec1'] = train['words'].apply(lambda x:doc2vec_m1(x,model))
test['vec1'] = test['words'].apply(lambda x:doc2vec_m1(x,model))    

fit_and_predicted(train['vec1'],train['label'],test['vec1'],test['label'])
#跑了一天。。按Ctrl+C不小心搞停了，崩啊


#3.4 优化上面的doc2vec_m1，使用列表推导来提速
def doc2vec_m2(text, model):
    """
    doc-to-vector,修改版2
    :param text:
    :param model:
    :return: 文本向量
    """
    return np.sum([model[word] for word in text if word in vocab], axis=0)

#还在跑。。
train['vec'] = train['words'].apply(lambda x:doc2vec_m1(x,model))
test['vec'] = test['words'].apply(lambda x:doc2vec_m1(x,model)) 

train[['label','words']].to_csv("train_label_words.csv",index=False)
test[['label','words']].to_csv("test_label_words.csv",index=False)

